{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from openai import OpenAI\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "from collections import  defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# 初始化知识图谱组件\n",
    "from OmniStore.chromadb_store import StoreTool\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from KnowledgeGraphManager.KGManager import KgManager\n",
    "import leidenalg\n",
    "from igraph import Graph as IGraph\n",
    "\n",
    "load_dotenv(dotenv_path=\"./.env\")\n",
    "\n",
    "\n",
    "device = os.getenv(\"DEVICE\")\n",
    "\n",
    "\n",
    "if os.getenv(\"IS_USE_LOCAL\") == \"True\":\n",
    "    embeddings = SentenceTransformer(\n",
    "        os.getenv(\"EMBEDDINGS_PATH\")\n",
    "    ).to(device)\n",
    "else:\n",
    "    # 初始化模型和组件\n",
    "    embeddings = SentenceTransformer(os.getenv(\"EMBEDDINGS\")).to(device)\n",
    "\n",
    "\n",
    "# 创建两个独立的存储工具\n",
    "chromadb_store = StoreTool(storage_path= os.getenv(\"CHROMADB_PATH\"), embedding_function=embeddings)\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\")\n",
    ")\n",
    "\n",
    "# 多模态模型\n",
    "vl_client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\"\n",
    "    api_key=os.getenv(\"VL_API_KEY\"),\n",
    "    base_url=os.getenv(\"VL_BASE_URL\")\n",
    ")\n",
    "from LLM.Openai_Agent import OpenaiAgent\n",
    "# 创建两个独立的agent\n",
    "rag_agent = OpenaiAgent(client)\n",
    "kg_agent = OpenaiAgent(client)\n",
    "\n",
    "# 创建两个独立的splitter\n",
    "simple_files = os.getenv(\"SIMPLE\", \"\").split(\",\")\n",
    "semantic_files = os.getenv(\"SEMANTIC\", \"\").split(\",\")\n",
    "character_files = os.getenv(\"CHARACTER\", \"\").split(\",\")\n",
    "\n",
    "# 初始化默认分割器\n",
    "kg_splitter = None\n",
    "\n",
    "# 创建默认分割器\n",
    "if len(simple_files) > 0:\n",
    "    from TextSlicer.SimpleTextSplitter import SimpleTextSplitter\n",
    "    kg_splitter = SimpleTextSplitter(2045, 1024)\n",
    "elif len(semantic_files) > 0:\n",
    "    from TextSlicer.SemanticTextSplitter import SemanticTextSplitter\n",
    "    kg_splitter = SemanticTextSplitter(2045, 1024)\n",
    "elif len(character_files) > 0:\n",
    "    from TextSlicer.CharacterTextSplitter import CharacterTextSplitter\n",
    "    kg_splitter = CharacterTextSplitter(separator=\"</end>\", keep_separator=False, max_tokens=2045, min_tokens=1024)\n",
    "\n",
    "# 创建两个独立的kg_manager\n",
    "kg_manager = KgManager(agent=kg_agent, splitter=kg_splitter, embedding_model=embeddings, store=chromadb_store)\n",
    "\n",
    "kg_manager.load_store(\"知识融合\")\n",
    "\n",
    "\n",
    "G = kg_manager.current_G\n",
    "G2 = kg_manager.current_G\n",
    "print(G)\n",
    "\n",
    "# ================== 社区划分算法部分 ==================\n",
    "# Louvain算法\n",
    "community_map = community_louvain.best_partition(G2.to_undirected())\n",
    "print(community_map, 2)\n",
    "\n",
    "# Leiden算法\n",
    "# 将networkx图转换为igraph图\n",
    "nodes = list(G2.nodes())\n",
    "node_id_map = {node: i for i, node in enumerate(nodes)}\n",
    "edges = [(node_id_map[u], node_id_map[v]) for u, v in G2.edges()]\n",
    "\n",
    "# 创建igraph图对象\n",
    "igraph_G = IGraph(directed=False)\n",
    "igraph_G.add_vertices(len(nodes))\n",
    "igraph_G.add_edges(edges)\n",
    "\n",
    "# 进行Leiden社区检测\n",
    "partition = leidenalg.find_partition(\n",
    "    igraph_G,\n",
    "    leidenalg.ModularityVertexPartition,\n",
    "    n_iterations=-1  # 使用无限迭代直到收敛\n",
    ")\n",
    "leiden_communities = partition.membership\n",
    "leiden_community_map = {node: leiden_communities[node_id_map[node]] for node in nodes}\n",
    "\n",
    "\n",
    "# ================== 可视化部分 ==================\n",
    "def visualize_communities(graph, community_dict, filename):\n",
    "    \"\"\"通用社区可视化函数\"\"\"\n",
    "    net = Network(height=\"600px\", width=\"100%\", notebook=True)\n",
    "\n",
    "    # 添加节点\n",
    "    for node in graph.nodes():\n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=str(node),\n",
    "            group=community_dict[node],\n",
    "            color=\"#%06x\" % (community_dict[node] * 0x0F0F0F)\n",
    "        )\n",
    "\n",
    "    # 添加边\n",
    "    for edge in graph.edges():\n",
    "        net.add_edge(edge[0], edge[1])\n",
    "\n",
    "    # 配置物理引擎\n",
    "    net.toggle_physics(True)\n",
    "    net.show(filename)\n",
    "\n",
    "\n",
    "class CommunityRetriever:\n",
    "    def __init__(self, graph, community_map):\n",
    "        \"\"\"\n",
    "        :param graph: NetworkX 图对象（带权重）\n",
    "        :param community_map: 社区划分字典 {节点: 社区ID}\n",
    "        \"\"\"\n",
    "        self.graph = graph\n",
    "        self.community_map = community_map\n",
    "        self._build_community_index()\n",
    "\n",
    "    def _build_community_index(self):\n",
    "        \"\"\"构建社区反向索引\"\"\"\n",
    "        self.community_index = defaultdict(list)\n",
    "        for node, comm_id in self.community_map.items():\n",
    "            self.community_index[comm_id].append(node)\n",
    "\n",
    "    def find_related_entities(self, query_entities, top_n=20):\n",
    "        \"\"\"\n",
    "        带权重的社区实体检索\n",
    "        :param query_entities: 查询实体列表\n",
    "        :param top_n: 返回每个实体的相关实体数量\n",
    "        :return: 排序后的相关实体字典\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for entity in query_entities:\n",
    "            if entity not in self.graph:\n",
    "                continue\n",
    "\n",
    "            # 获取实体所属社区\n",
    "            comm_id = self.community_map.get(entity, -1)\n",
    "            community_nodes = self.community_index.get(comm_id, [])\n",
    "\n",
    "            # 计算相关性分数\n",
    "            scores = []\n",
    "            for node in community_nodes:\n",
    "                if node == entity:\n",
    "                    continue\n",
    "\n",
    "                # 计算路径权重（考虑直接连接和多跳关系）\n",
    "                try:\n",
    "                    # 获取最短路径\n",
    "                    path = nx.shortest_path(self.graph, source=entity, target=node)\n",
    "                    # 计算路径权重总和\n",
    "                    path_weight = sum(\n",
    "                        self.graph[path[i]][path[i + 1]].get('weight', 1)\n",
    "                        for i in range(len(path) - 1)\n",
    "                    )\n",
    "                    # 标准化处理：路径权重均值\n",
    "                    score = path_weight / len(path)\n",
    "                except nx.NetworkXNoPath:\n",
    "                    score = 0\n",
    "\n",
    "                scores.append((node, score))\n",
    "\n",
    "            # 按分数降序排序\n",
    "            sorted_entities = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "            results[entity] = {\n",
    "                'community': comm_id,\n",
    "                'related': sorted_entities[:top_n]\n",
    "            }\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# 生成Louvain可视化\n",
    "visualize_communities(G, community_map, \"louvain_community.html\")\n",
    "\n",
    "# 生成Leiden可视化\n",
    "visualize_communities(G, leiden_community_map, \"leiden_community.html\")\n",
    "\n",
    "# 初始化检索器（使用Louvain社区划分）\n",
    "louvain_retriever = CommunityRetriever(G.to_undirected(), community_map)\n",
    "\n",
    "# 初始化检索器（使用Leiden社区划分）\n",
    "leiden_retriever = CommunityRetriever(G.to_undirected(), leiden_community_map)\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设用户问题中的实体列表\n",
    "    query_entities = [\"牛顿力学\", \"星海科技\",\"经典物理\"]\n",
    "\n",
    "    # 使用Louvain算法的检索结果\n",
    "    louvain_result = louvain_retriever.find_related_entities(query_entities)\n",
    "    print(\"Louvain社区检索结果：\")\n",
    "    print(json.dumps(louvain_result, indent=5, ensure_ascii=False))\n",
    "\n",
    "    # 使用Leiden算法的检索结果\n",
    "    leiden_result = leiden_retriever.find_related_entities(query_entities)\n",
    "    print(\"\\nLeiden社区检索结果：\")\n",
    "    print(json.dumps(leiden_result, indent=5, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
