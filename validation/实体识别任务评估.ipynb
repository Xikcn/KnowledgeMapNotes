{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T01:23:08.655622Z",
     "start_time": "2025-06-04T01:23:08.633261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用Dask（超大规模数据）\n",
    "import dask.dataframe as dd\n",
    "ddf = dd.read_parquet(\"test-00000-of-00001.parquet\", engine=\"pyarrow\")\n",
    "result = ddf.compute()\n",
    "result"
   ],
   "id": "b92f3a7fcae391b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                tokens  \\\n",
       "0     [一, 节, 课, 的, 时, 间, 真, 心, 感, 动, 了, 李, 开, 复, 感, 动]   \n",
       "1    [回, 复, 支, 持, ，, 赞, 成, ，, 哈, 哈, 米, 八, 吴, 够, 历, ...   \n",
       "2    [剑, 网, 乱, 世, 长, 安, 公, 测, 盛, 典, 今, 日, 开, 启, ，, ...   \n",
       "3    [在, 街, 上, 听, 见, 音, 乐, 我, 舞, 动, 起, 来, 很, 丢, 人, ...   \n",
       "4    [三, 毛, 说, 我, 唯, 一, 锲, 而, 不, 舍, ，, 愿, 意, 以, 自, ...   \n",
       "..                                                 ...   \n",
       "265  [么, 儿, ！, [, 爱, 你, ], /, /, @, 微, 博, 搞, 笑, 排, ...   \n",
       "266  [感, 恩, 大, 回, 馈, ，, 孟, 小, 帅, 沈, 阳, 店, 专, 属, 活, ...   \n",
       "267  [我, 叫, 赵, 新, 民, 我, 也, 要, 吃, 斤, 刚, 刚, 好, 呢, 肉, ...   \n",
       "268  [#, 微, 博, 益, 起, 来, #, 努, 力, 加, 油, O, (, ∩, _, ...   \n",
       "269  [国, 安, 老, 球, 迷, 辣, 笔, 小, 辛, 令, 人, 尊, 敬, 的, 老, ...   \n",
       "\n",
       "                                              ner_tags  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, ...  \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [13, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "..                                                 ...  \n",
       "265  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "266  [0, 0, 0, 0, 0, 0, 9, 10, 10, 10, 10, 10, 0, 0...  \n",
       "267  [0, 0, 13, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "268  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "269  [9, 10, 15, 16, 16, 13, 14, 14, 14, 0, 0, 0, 0...  \n",
       "\n",
       "[270 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[一, 节, 课, 的, 时, 间, 真, 心, 感, 动, 了, 李, 开, 复, 感, 动]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[回, 复, 支, 持, ，, 赞, 成, ，, 哈, 哈, 米, 八, 吴, 够, 历, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[剑, 网, 乱, 世, 长, 安, 公, 测, 盛, 典, 今, 日, 开, 启, ，, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[在, 街, 上, 听, 见, 音, 乐, 我, 舞, 动, 起, 来, 很, 丢, 人, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[三, 毛, 说, 我, 唯, 一, 锲, 而, 不, 舍, ，, 愿, 意, 以, 自, ...</td>\n",
       "      <td>[13, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>[么, 儿, ！, [, 爱, 你, ], /, /, @, 微, 博, 搞, 笑, 排, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>[感, 恩, 大, 回, 馈, ，, 孟, 小, 帅, 沈, 阳, 店, 专, 属, 活, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 9, 10, 10, 10, 10, 10, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>[我, 叫, 赵, 新, 民, 我, 也, 要, 吃, 斤, 刚, 刚, 好, 呢, 肉, ...</td>\n",
       "      <td>[0, 0, 13, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>[#, 微, 博, 益, 起, 来, #, 努, 力, 加, 油, O, (, ∩, _, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>[国, 安, 老, 球, 迷, 辣, 笔, 小, 辛, 令, 人, 尊, 敬, 的, 老, ...</td>\n",
       "      <td>[9, 10, 15, 16, 16, 13, 14, 14, 14, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T01:34:36.212863Z",
     "start_time": "2025-06-04T01:34:35.394489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "# 处理文本\n",
    "nlp = spacy.load('zh_core_web_sm')\n",
    "doc = nlp(\"\"\"\n",
    "#计算机科学1. 哈希表-哈希表（Hash Table）是一种数据结构，通过键值对存储数据。- 它使用哈希函数计算键的索引，实现O(1)时间复杂度的查找。- 冲突解决方法：链地址法（Chaining）、开放寻址法（Open Addressing）。2. 深度学习- 神经网络由输入层、隐藏层、输出层组成。- 反向传播用于优化模型参数。- 常见框架：PyTorch、TensorFlow。# 数学1. 贝叶斯定理- P(A|B) = P(B|A) * P(A) / P(B)- 用于概率推断，如垃圾邮件分类。2. 线性代数- 矩阵乘法不满足交换律：A×B ≠ B×A。- 特征值和特征向量：Av = λv。\n",
    "\"\"\")\n",
    "\n",
    "# 遍历识别出的实体\n",
    "for ent in doc.ents:\n",
    "    # 打印实体文本及其标注\n",
    "    print(ent.text, ent.label_)"
   ],
   "id": "f0e356a5f34db9f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 哈希表 QUANTITY\n",
      "哈希表 PERSON\n",
      "Hash Table PERSON\n",
      "数计算键 CARDINAL\n",
      "1 CARDINAL\n",
      "2 CARDINAL\n",
      "1. CARDINAL\n",
      "贝叶斯 GPE\n",
      "2 CARDINAL\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T01:41:04.549211Z",
     "start_time": "2025-06-04T01:41:04.540983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_to_entity_list(tokens, ner_tags):\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    current_b_tag = None\n",
    "\n",
    "    for token, tag in zip(tokens, ner_tags):\n",
    "        if tag == 0:  # O 标签\n",
    "            if current_entity:\n",
    "                entities.append(\"\".join(current_entity))\n",
    "                current_entity = []\n",
    "                current_b_tag = None\n",
    "        elif tag % 2 == 1:  # B 标签 (奇数)\n",
    "            if current_entity:\n",
    "                entities.append(\"\".join(current_entity))\n",
    "            current_entity = [token]\n",
    "            current_b_tag = tag\n",
    "        elif tag % 2 == 0:  # I 标签 (偶数)\n",
    "            if current_b_tag is not None and tag == current_b_tag + 1:\n",
    "                current_entity.append(token)\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append(\"\".join(current_entity))\n",
    "\n",
    "    return entities\n",
    "\n",
    "# 示例使用\n",
    "tokens = [\"这\",\"次\",\"代\",\"表\",\"大\",\"会\",\"是\",\"在\",\"中\",\"国\",\"改\",\"革\",\"开\",\"放\",\"和\",\"社\",\"会\",\"主\",\"义\",\"现\",\"代\",\"化\",\"建\",\"设\",\"发\",\"展\",\"的\",\"关\",\"键\",\"时\",\"刻\",\"召\",\"开\",\"的\",\"历\",\"史\",\"性\",\"会\",\"议\",\"。\"]\n",
    "ner_tags = [0,0,0,0,0,0,0,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "x = \"\".join(tokens)  # \"这次代表大会是在中国改革开放和社会主义现代化建设发展的关键时刻召开的历史性会议。\"\n",
    "y = convert_to_entity_list(tokens, ner_tags)  # [\"中国\"]\n",
    "x,y"
   ],
   "id": "2f0557ae85fe40c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('这次代表大会是在中国改革开放和社会主义现代化建设发展的关键时刻召开的历史性会议。', ['中国'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T01:52:03.107963Z",
     "start_time": "2025-06-04T01:52:03.071279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "def convert_to_entity_list(row):\n",
    "    \"\"\"\n",
    "    将单行数据转换为实体列表\n",
    "    输入: 包含tokens和ner_tags的DataFrame行\n",
    "    输出: (完整文本, 实体列表) 的元组\n",
    "    \"\"\"\n",
    "    tokens = row['tokens']\n",
    "    ner_tags = row['ner_tags']\n",
    "\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    current_b_tag = None\n",
    "\n",
    "    try:\n",
    "        for token, tag in zip(tokens, ner_tags):\n",
    "            if tag == 0:  # O标签\n",
    "                if current_entity:\n",
    "                    entities.append(\"\".join(current_entity))\n",
    "                    current_entity = []\n",
    "                    current_b_tag = None\n",
    "            elif tag % 2 == 1:  # B标签 (实体起始)\n",
    "                if current_entity:\n",
    "                    entities.append(\"\".join(current_entity))\n",
    "                current_entity = [token]\n",
    "                current_b_tag = tag\n",
    "            elif tag % 2 == 0:  # I标签 (实体内部)\n",
    "                if current_b_tag is not None and tag == current_b_tag + 1:\n",
    "                    current_entity.append(token)\n",
    "\n",
    "        if current_entity:\n",
    "            entities.append(\"\".join(current_entity))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"实体提取失败: {e}\")\n",
    "        entities = []  # 错误时返回空列表\n",
    "\n",
    "    # 将分词列表合并为完整文本\n",
    "    full_text = \"\".join(tokens)\n",
    "\n",
    "    return pd.Series({\n",
    "        'x': full_text,\n",
    "        'y': entities  # 保持为列表类型\n",
    "    })\n",
    "\n",
    "# ===== 主处理流程 =====\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 读取原始Parquet文件\n",
    "    ddf = dd.read_parquet(\n",
    "        \"test-00000-of-00001.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "        blocksize=\"128MB\",  # 优化分块大小[1,3](@ref)\n",
    "        columns=['tokens', 'ner_tags']  # 仅加载必要列[2](@ref)\n",
    "    )\n",
    "\n",
    "    # 2. 应用转换函数（显示进度条）\n",
    "    with ProgressBar():  # 添加进度监控[3](@ref)\n",
    "        new_ddf = ddf.map_partitions(\n",
    "            lambda df: df.apply(convert_to_entity_list, axis=1),\n",
    "            meta={'x': 'str', 'y': 'object'}  # 指定输出类型[5](@ref)\n",
    "        )\n",
    "\n",
    "    # 3. 定义明确的Parquet schema（关键修复）[1,4,7](@ref)\n",
    "    schema = pa.schema([\n",
    "        ('x', pa.string()),          # 文本列：字符串类型\n",
    "        ('y', pa.list_(pa.string())) # 实体列：字符串列表类型\n",
    "    ])\n",
    "\n",
    "    # 4. 保存为新的Parquet文件（显式指定schema）\n",
    "    new_ddf.to_parquet(\n",
    "        \"processed_dataset\",\n",
    "        engine=\"pyarrow\",\n",
    "        schema=schema,  # 显式定义schema解决类型错误[5,7](@ref)\n",
    "        compression=\"snappy\",  # 优化压缩格式[1,2](@ref)\n",
    "        write_index=False,\n",
    "        overwrite=True,\n",
    "        compute_kwargs={'scheduler': 'threads'}  # 多线程写入加速[3](@ref)\n",
    "    )\n",
    "\n",
    "    print(\"处理完成！输出保存在 processed_dataset 目录\")"
   ],
   "id": "e4d291bc9677c966",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！输出保存在 processed_dataset 目录\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T03:41:22.844082Z",
     "start_time": "2025-06-04T03:41:22.831134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用Dask（超大规模数据）\n",
    "import dask.dataframe as dd\n",
    "ddf = dd.read_parquet(\"processed_dataset/part.0.parquet\", engine=\"pyarrow\")\n",
    "result = ddf.compute()\n",
    "result"
   ],
   "id": "31f9923bae123f16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     x  \\\n",
       "0                                     一节课的时间真心感动了李开复感动   \n",
       "1    回复支持，赞成，哈哈米八吴够历史要的陈小奥丁丁我爱小肥肥一族大头仔大家团结一致，誓要去台湾饮...   \n",
       "2    剑网乱世长安公测盛典今日开启，海量豪礼火爆开送精美挂件、听雨·汉服娃娃、诙谐双骑独轮车等你来...   \n",
       "3                              在街上听见音乐我舞动起来很丢人？真的很丢人吗？   \n",
       "4    三毛说我唯一锲而不舍，愿意以自己的生命去努力的，只不过是保守我个人的心怀意念，在我有生之日，...   \n",
       "..                                                 ...   \n",
       "265                   么儿！[爱你]//@微博搞笑排行榜:想要这个蛋糕[花心][花心]   \n",
       "266                感恩大回馈，孟小帅沈阳店专属活动http://t.cn/Rhnxj3A   \n",
       "267  我叫赵新民我也要吃斤刚刚好呢肉包纸？这货竟然是肉包纸太萌了吧伦家都不舍得吃啦喜欢吃，就关注吃...   \n",
       "268           #微博益起来#努力加油O(∩_∩)O我在:http://t.cn/8khf0QM   \n",
       "269  国安老球迷辣笔小辛令人尊敬的老先生，同时，同意右侧观点。北晚小赢家这是真球迷，不是那些喜欢搞...   \n",
       "\n",
       "                                 y  \n",
       "0                            [李开复]  \n",
       "1                        [陈小奥, 台湾]  \n",
       "2                               []  \n",
       "3                               []  \n",
       "4                             [三毛]  \n",
       "..                             ...  \n",
       "265                             []  \n",
       "266                       [孟小帅沈阳店]  \n",
       "267                      [赵新民, 吃货]  \n",
       "268                             []  \n",
       "269  [国安, 老球迷, 辣笔小辛, 老先生, 球迷, 死忠们]  \n",
       "\n",
       "[270 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一节课的时间真心感动了李开复感动</td>\n",
       "      <td>[李开复]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>回复支持，赞成，哈哈米八吴够历史要的陈小奥丁丁我爱小肥肥一族大头仔大家团结一致，誓要去台湾饮...</td>\n",
       "      <td>[陈小奥, 台湾]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>剑网乱世长安公测盛典今日开启，海量豪礼火爆开送精美挂件、听雨·汉服娃娃、诙谐双骑独轮车等你来...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>在街上听见音乐我舞动起来很丢人？真的很丢人吗？</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>三毛说我唯一锲而不舍，愿意以自己的生命去努力的，只不过是保守我个人的心怀意念，在我有生之日，...</td>\n",
       "      <td>[三毛]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>么儿！[爱你]//@微博搞笑排行榜:想要这个蛋糕[花心][花心]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>感恩大回馈，孟小帅沈阳店专属活动http://t.cn/Rhnxj3A</td>\n",
       "      <td>[孟小帅沈阳店]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>我叫赵新民我也要吃斤刚刚好呢肉包纸？这货竟然是肉包纸太萌了吧伦家都不舍得吃啦喜欢吃，就关注吃...</td>\n",
       "      <td>[赵新民, 吃货]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>#微博益起来#努力加油O(∩_∩)O我在:http://t.cn/8khf0QM</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>国安老球迷辣笔小辛令人尊敬的老先生，同时，同意右侧观点。北晚小赢家这是真球迷，不是那些喜欢搞...</td>\n",
       "      <td>[国安, 老球迷, 辣笔小辛, 老先生, 球迷, 死忠们]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4afb58968f739822"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
